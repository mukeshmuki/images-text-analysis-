{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02053d09-d44a-4cee-912d-e7c74774e998",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8060/\n"
     ]
    }
   ],
   "source": [
    "######Initializing all the python packages for building dashboard\n",
    "\n",
    "###Refer to the official Dash website to understand the syntax better\n",
    "\n",
    "import datetime\n",
    "\n",
    "from dash import Dash, dcc, html\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_table_experiments as dt\n",
    "from dash import Dash, dash_table\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "#app = JupyterDash(external_stylesheets=external_stylesheets)\n",
    "\n",
    "app = JupyterDash()  #####This is to run the code through Jupyter lab\n",
    "\n",
    "####Function to print the obtained result python dataframe as a table through HTML\n",
    "def generate_table(dataframe, max_rows=10):\n",
    "    return html.Table([\n",
    "        html.Thead(\n",
    "            html.Tr([html.Th(col) for col in dataframe.columns])\n",
    "        ),\n",
    "        html.Tbody([\n",
    "            html.Tr([\n",
    "                html.Td(dataframe.iloc[i][col]) for col in dataframe.columns\n",
    "            ]) for i in range(min(len(dataframe), max_rows))\n",
    "        ])\n",
    "    ])\n",
    "\n",
    "def img_conv():\n",
    "    import sys\n",
    "    from PIL import Image\n",
    "    from io import BytesIO\n",
    "    import base64\n",
    "    \n",
    "    content_type, content_string = aa[0].split(',')\n",
    "    decoded = base64.b64decode(content_string)\n",
    "\n",
    "    stream = BytesIO(decoded)\n",
    "\n",
    "    image = Image.open(stream).convert(\"RGBA\")\n",
    "    stream.close()\n",
    "    image.save(\"img.png\")\n",
    "\n",
    "    import cv2\n",
    "    img = cv2.imread(\"img.png\")   ####Reading the uploaded image\n",
    "    img_text(img)\n",
    "\n",
    "def img_text(image):\n",
    "\n",
    "    import os\n",
    "\n",
    "    import pandas as pd\n",
    "    from matplotlib import pyplot as plt\n",
    "    from easyocr import Reader ###Pretrained text extraction model from an AI company JaidedAI\n",
    "\n",
    "    #from IPython.display import clear_output\n",
    "    #import time \n",
    "\n",
    "    import re\n",
    "    import nltk #####NLP Packages to do text analysis\n",
    "\n",
    "    langs = ['en']   \n",
    "    reader = Reader(langs, gpu=0)\n",
    "    \n",
    "    print(\"1\")\n",
    "    ###Reading text from Image ####\n",
    "    def plt_imshow(title, image):\n",
    "        # convert the image frame BGR to RGB color space and display it\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(image)\n",
    "        plt.title(title)\n",
    "        plt.grid(False)\n",
    "        plt.show()\n",
    "\n",
    "    def cleanup_text(text):\n",
    "        # strip out non-ASCII text so we can draw the text on the image\n",
    "        # using OpenCV\n",
    "        return \"\".join([c if ord(c) < 128 else \"\" for c in text]).strip()\n",
    "    img = image\n",
    "    img_name = 'img.png'\n",
    "\n",
    "    pix = 0\n",
    "    cnt = 0\n",
    "\n",
    "    img_nme = []\n",
    "    pix_perc = []\n",
    "\n",
    "    txt_pix = []\n",
    "    img_pix = []\n",
    "    per_pix = []\n",
    "    per_perc = []\n",
    "\n",
    "    width = []\n",
    "    height = []\n",
    "\n",
    "    contr =[]\n",
    "    contr_r =[]\n",
    "    pers_cnt =[]\n",
    "    txtt = []\n",
    "    na_i = []\n",
    "\n",
    "    txt = []\n",
    "    shape = (img.shape[0] * img.shape[1])\n",
    "\n",
    "    img_grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    contrast_r = img_grey.std()  ###to calculate the contrast of the image\n",
    "\n",
    "    print(\"2\")\n",
    "    results = reader.readtext(img)\n",
    "\n",
    "    print(\"4\")\n",
    "    for (bbox, text, prob) in results:\n",
    "        #if \"unacademy\" in text:\n",
    "\n",
    "        (tl, tr, br, bl) = bbox\n",
    "        tl = (int(tl[0]), int(tl[1]))\n",
    "        tr = (int(tr[0]), int(tr[1]))\n",
    "        br = (int(br[0]), int(br[1]))\n",
    "        bl = (int(bl[0]), int(bl[1]))\n",
    "\n",
    "        wid = br[0] - tl[0]\n",
    "        hgt = br[1] - tl[1]\n",
    "\n",
    "        pix1 = wid * hgt\n",
    "        pix = pix + pix1\n",
    "\n",
    "        text = cleanup_text(text)\n",
    "        txt.append(text)\n",
    "\n",
    "        pix_per = round((pix / shape ) * 100,2)\n",
    "\n",
    "    img_pix.append(shape)\n",
    "    txt_pix.append(pix)\n",
    "\n",
    "    txtt.append(txt)\n",
    "    img_nme.append(img_name)\n",
    "    pix_perc.append(pix_per)\n",
    "\n",
    "    contr_r.append(contrast_r)\n",
    "    height.append(img.shape[0])\n",
    "    width.append(img.shape[1])\n",
    "    dtf = pd.DataFrame(list(zip(img_nme, img_pix, txt_pix, pix_perc, txtt,\n",
    "                                        contr_r, width, height )), \n",
    "                columns =['Image', 'Image_pixels', 'Text_pixels', 'text_perc', 'text', \n",
    "                           'contrast_r', 'width', 'height']) \n",
    "\n",
    "    def utils_preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=None):\n",
    "        text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "\n",
    "        ## Tokenize (convert from string to list)\n",
    "        lst_text = text.split()\n",
    "        ## remove Stopwords\n",
    "        if lst_stopwords is not None:\n",
    "            lst_text = [word for word in lst_text if word not in \n",
    "                        lst_stopwords]\n",
    "\n",
    "        ## Stemming (remove -ing, -ly, ...)\n",
    "        if flg_stemm == True:\n",
    "            ps = nltk.stem.porter.PorterStemmer()\n",
    "            lst_text = [ps.stem(word) for word in lst_text]\n",
    "\n",
    "        ## Lemmatisation (convert the word into root word)\n",
    "        if flg_lemm == True:\n",
    "            lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "            lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "\n",
    "        ## back to string from list\n",
    "        text = \" \".join(lst_text)\n",
    "        return text\n",
    "\n",
    "    dtf[\"text_clean\"] = dtf[\"text\"].apply(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True, lst_stopwords = None))\n",
    "\n",
    "    dtf['word_count'] = dtf[\"text\"].apply(lambda x: len(str(x).split(\" \")))\n",
    "    dtf['char_count'] = dtf[\"text\"].apply(lambda x: sum(len(word) for word in str(x).split(\" \")))\n",
    "    dtf['sentence_count'] = dtf[\"text\"].apply(lambda x: len(str(x).split(\".\")))\n",
    "    dtf['avg_word_length'] = round(dtf['char_count'] / dtf['word_count'],0)\n",
    "    dtf['avg_sentence_lenght'] = dtf['word_count'] / dtf['sentence_count']\n",
    "\n",
    "    dtf1 = dtf[['Image', 'text_perc', 'word_count' , 'avg_word_length']]\n",
    "    \n",
    "    global df1\n",
    "    df1 = dtf1\n",
    "    print(\"code run successfully\")\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Upload(\n",
    "        id='upload-image',\n",
    "        children=html.Div([\n",
    "            'Drag and Drop or ',\n",
    "            html.A('Select Files')\n",
    "        ]),\n",
    "        style={\n",
    "            'width': '100%',\n",
    "            'height': '60px',\n",
    "            'lineHeight': '60px',\n",
    "            'borderWidth': '1px',\n",
    "            'borderStyle': 'dashed',\n",
    "            'borderRadius': '5px',\n",
    "            'textAlign': 'center',\n",
    "            'margin': '10px'\n",
    "        },\n",
    "        # Allow multiple files to be uploaded\n",
    "        multiple=True\n",
    "    ),\n",
    "    html.Div(id='output-image-upload'),\n",
    "    \n",
    "        html.Hr(),\n",
    "    \n",
    " ])\n",
    "\n",
    "def parse_contents(contents, filename, date):\n",
    "    return html.Div([\n",
    "        html.H6(filename),\n",
    "        html.Img(src=contents, width = 500),\n",
    "        html.Hr(),\n",
    "        generate_table(df1),\n",
    "        html.Hr(),\n",
    "        html.H6('Recommended text percent : < 19'), #####Mention your own metrics which you need to control\n",
    "        html.H6('Recommended word count : < 18'),\n",
    "        html.H6('Average word length : 6 to 8')\n",
    "          ])\n",
    "\n",
    "@app.callback(Output('output-image-upload', 'children'),\n",
    "              Input('upload-image', 'contents'),\n",
    "              State('upload-image', 'filename'),\n",
    "              State('upload-image', 'last_modified'))\n",
    "def update_output(list_of_contents, list_of_names, list_of_dates):\n",
    "    if list_of_contents is not None:\n",
    "        global aa\n",
    "        aa = list_of_contents\n",
    "        \n",
    "        global bb\n",
    "        bb = list_of_names\n",
    "        img_conv()\n",
    "        children = [\n",
    "            parse_contents(c, n, d) for c, n, d in\n",
    "            zip(list_of_contents, list_of_names, list_of_dates)\n",
    "        ]\n",
    "        return children\n",
    "\n",
    "    \n",
    "app.run_server(mode='external', port=8060)   ####Mention the server you need to run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec72f4d5-d562-4112-b806-558006bb0bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90432a0e-a8a1-41b1-90d7-31f10efa10cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61db956-d22c-4935-a8e7-8dc57cf3698e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
